{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "objectServallience.ipynb",
      "provenance": [],
      "mount_file_id": "11tOlAq-AVNb0DBFHWIRsEY-esYjRgEqv",
      "authorship_tag": "ABX9TyMUIS3Ixd1yvy4tXG3ApyQG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brkuhgk/yolo/blob/master/objectServallience.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0v_18C00XvLM"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import math\n",
        "import time\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDe3CCqwX9TS",
        "outputId": "91b51625-1ad1-4061-c762-9b6b2cc67478"
      },
      "source": [
        "#drive/MyDrive/new/yolo/\n",
        "\n",
        "#load yolo3\n",
        "start =time.time()\n",
        "\n",
        "net = cv2.dnn.readNet(\"drive/MyDrive/new/yolo/yolov3.weights\", \"drive/MyDrive/new/yolo/yolov3.cfg\")\n",
        "classes = []\n",
        "with open(\"drive/MyDrive/new/yolo/coco.names\", \"r\") as f:\n",
        "    classes = [line.strip() for line in f.readlines()]\n",
        "layer_names = net.getLayerNames()\n",
        "output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
        "colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
        "\n",
        "end= time.time()\n",
        "print(\"To load yolo3 time :\",end-start)\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "To load yolo3 time : 0.3097524642944336\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tjZsG20Ym1p"
      },
      "source": [
        "#vediocapture\n",
        "vediocap = cv2.VideoCapture('Thief Stealing Handbag from a Car 350.mp4')\n",
        "vediocap.set(cv2.CAP_PROP_FRAME_WIDTH,640)\n",
        "vediocap.set(cv2.CAP_PROP_FRAME_HEIGHT,480)\n",
        "vediocap.set(cv2.CAP_PROP_FPS, 30) \n",
        "\n",
        "writer = None\n",
        "(height,width) = (None, None)\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ia074QwGYuRh"
      },
      "source": [
        "while vediocap.isOpened():\n",
        "    ret, frame = vediocap.read()\n",
        "    \n",
        "    if not ret:\n",
        "        break\n",
        "    \n",
        "    #if frame dimensions are empty\n",
        "    if width is None or height is None: \n",
        "        (height, width) = frame.shape[:2]\n",
        "    \n",
        "    #320×320 it’s small so less accuracy but better speed\n",
        "    #609×609 it’s bigger so high accuracy and slow speed\n",
        "    #416×416 it’s in the middle and you get a bit of both.\n",
        "    \n",
        "    start =time.time()\n",
        "    # Detecting objects\n",
        "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
        "    net.setInput(blob)\n",
        "    \n",
        "    outs = net.forward(output_layers)\n",
        "    \n",
        "    \n",
        "    # Showing informations on the screen\n",
        "    class_ids = []\n",
        "    confidences = []\n",
        "    boxes = []\n",
        "    for out in outs:\n",
        "        for detection in out:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "            if confidence > 0.5:\n",
        "                # Object detected\n",
        "                center_x = int(detection[0] * width)\n",
        "                center_y = int(detection[1] * height)\n",
        "                w = int(detection[2] * width)\n",
        "                h = int(detection[3] * height)\n",
        "\n",
        "                # Rectangle coordinates\n",
        "                x = int(center_x - w / 2)\n",
        "                y = int(center_y - h / 2)\n",
        "\n",
        "                boxes.append([x, y, w, h])\n",
        "                confidences.append(float(confidence))\n",
        "                class_ids.append(class_id)\n",
        "    \n",
        "    #to remove the noise\n",
        "    #Non maximum suppresion.\n",
        "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4) #0.5 =confidence ,Threshold =0.4\n",
        "    \n",
        "    \n",
        "    \n",
        "    #atleast one is detection exists\n",
        "    if(len(indexes) >0):\n",
        "        font = cv2.FONT_HERSHEY_PLAIN\n",
        "        for i in range(len(boxes)):\n",
        "            if i in indexes:\n",
        "                x, y, w, h = boxes[i]\n",
        "                label = str(classes[class_ids[i]])\n",
        "                color = colors[i]\n",
        "                cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
        "                cv2.putText(frame, label, (x, y + 30), font, 3, color, 3)\n",
        "        \n",
        "    \n",
        "    \n",
        "    \n",
        "    # check if the video writer is None\n",
        "    if writer is None:\n",
        "        # initialize our video writer\n",
        "        fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
        "        writer = cv2.VideoWriter(\"output_stealing_from_car_1.avi\", fourcc, 30,(frame.shape[1], frame.shape[0]), True)\n",
        "        \n",
        "    writer.write(frame)\n",
        "    cv2_imshow(frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "    \n",
        "        \n",
        "\n",
        "vediocap.release()\n",
        "# writer.release()\n",
        "cv2.destroyAllWindows()\n",
        "end =time.time()\n",
        "print(\"time taken : \",end -start)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}